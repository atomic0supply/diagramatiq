version: '3.8'

services:
  # ü¶ô Ollama - IA Local (NECESARIO)
  ollama:
    image: ollama/ollama:latest
    container_name: diagramatiq-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
    networks:
      - diagramatiq-network
    restart: unless-stopped
    # GPU support (opcional)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # üöÄ Backend API (FastAPI) - Para desarrollo futuro
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    container_name: diagramatiq-backend
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
    depends_on:
      - ollama
    networks:
      - diagramatiq-network
    restart: unless-stopped
    volumes:
      - ./backend:/app
    profiles:
      - with-backend  # Solo con: docker-compose --profile with-backend up

  # üåê Frontend (Next.js) - Desarrollo
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: diagramatiq-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_OLLAMA_HOST=http://localhost:11434
      - NEXT_PUBLIC_BACKEND_HOST=http://localhost:8080
      - NEXT_PUBLIC_PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    networks:
      - diagramatiq-network
    depends_on:
      - ollama
    profiles:
      - with-frontend  # Solo con: docker-compose --profile with-frontend up

# üì¶ Vol√∫menes persistentes
volumes:
  ollama-data:
    driver: local

# üåê Red interna
networks:
  diagramatiq-network:
    driver: bridge